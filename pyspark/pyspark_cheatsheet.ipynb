{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "findspark.find()\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Setting up the SparkContext\n",
    "conf = pyspark.SparkConf().setAppName('appName').setMaster('local')\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load a random csv input dataset for example\n",
    "INPUT_PATH = \".../inputs/BEV325OD3250.csv\"\n",
    "\n",
    "df = spark.read\\\n",
    "          .option(\"header\", True)\\\n",
    "          .option(\"inferSchema\", True)\\\n",
    "          .option(\"delimiter\", \",\")\\\n",
    "          .csv(INPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (190680, 17) \n",
      "\n",
      "Nbr of partitions: 1 \n",
      "\n",
      "---- Schema ----\n",
      "root\n",
      " |-- StichtagDatJahr: integer (nullable = true)\n",
      " |-- StichtagDatMM: integer (nullable = true)\n",
      " |-- StichtagDatMonat: string (nullable = true)\n",
      " |-- StichtagDat: integer (nullable = true)\n",
      " |-- SexCd: integer (nullable = true)\n",
      " |-- SexLang: string (nullable = true)\n",
      " |-- AlterV20Sort: integer (nullable = true)\n",
      " |-- AlterV20Kurz: string (nullable = true)\n",
      " |-- HerkunftCd: integer (nullable = true)\n",
      " |-- HerkunftLang: string (nullable = true)\n",
      " |-- KreisCd: integer (nullable = true)\n",
      " |-- KreisLang: string (nullable = true)\n",
      " |-- QuarCd: integer (nullable = true)\n",
      " |-- QuarLang: string (nullable = true)\n",
      " |-- DatenstandCd: string (nullable = true)\n",
      " |-- DatenstandLang: string (nullable = true)\n",
      " |-- AnzBestWir: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### General information about our dataframe\n",
    "print(\"Shape: \", (df.count(), len(df.columns)), \"\\n\")\n",
    "print(\"Nbr of partitions:\", df.rdd.getNumPartitions(), \"\\n\")\n",
    "print(\"---- Schema ----\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Deduplication by filtering\n",
    "\n",
    "# Depending on the use case, one may need F.rank or F.row_number instead of F.dense_rank\n",
    "def deduper(table):\n",
    "    PARTITION = [\n",
    "        \"StichtagDatJahr\",\n",
    "        \"KreisLang\",\n",
    "        \"QuarLang\",\n",
    "        \"AlterV20Kurz\",\n",
    "        \"HerkunftLang\",\n",
    "        \"SexLang\"\n",
    "    ]\n",
    "    w = Window.partitionBy(PARTITION)\\\n",
    "              .orderBy(F.col(\"StichtagDatMM\").desc(), F.col(\"StichtagDat\").desc())\n",
    "    \n",
    "    return table.select(\"*\", F.dense_rank().over(w).alias(\"rn\"))\\\n",
    "                .filter(F.col(\"rn\") == 1)\\\n",
    "                .drop(\"rn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+------------------+-------------------+------------------+\n",
      "|StichtagDatJahr|1_new_StichtagDatMM|1_new_AlterV20Sort|2_new_StichtagDatMM|2_new_AlterV20Sort|\n",
      "+---------------+-------------------+------------------+-------------------+------------------+\n",
      "|           2003|              26316|             12107|              26389|             12150|\n",
      "|           2007|              26454|             12185|              26325|             12071|\n",
      "|           2018|              26520|             12240|              26519|             12235|\n",
      "|           2015|              26454|             12185|              26520|             12240|\n",
      "|           2006|              26439|             12160|              26232|             12010|\n",
      "|           2013|              26520|             12240|              26520|             12240|\n",
      "|           2014|              26454|             12185|              26520|             12240|\n",
      "|           2019|              26520|             12240|              26586|             12273|\n",
      "|           2004|              26386|             12130|              26311|             12075|\n",
      "|           1998|              26431|             12175|              26520|             12240|\n",
      "|           2020|              26520|             12240|              26569|             12256|\n",
      "|           2012|              26454|             12185|              26520|             12240|\n",
      "|           2009|              26454|             12165|              26492|             12205|\n",
      "|           2016|              26454|             12185|              26520|             12240|\n",
      "|           2001|              26298|             12065|              26509|             12235|\n",
      "|           2005|              26364|             12120|              26279|             12059|\n",
      "|           2000|              26292|             12050|              26520|             12240|\n",
      "|           2010|              26520|             12240|              26520|             12240|\n",
      "|           2011|              26490|             12225|              26520|             12240|\n",
      "|           2008|              26404|             12160|              26436|             12165|\n",
      "+---------------+-------------------+------------------+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Multi aggregation\n",
    "\n",
    "# It is more efficient to specify the values in the pivot function, so that Spark doesn't need\n",
    "# to first compute the list of distinct values internally.\n",
    "\n",
    "def multi_aggr(table):\n",
    "    AGGR = [F.sum(F.col(c)).alias(\"new_\" + c) for c in [\"StichtagDatMM\", \"AlterV20Sort\"]]\n",
    "    return table.groupBy(\"StichtagDatJahr\")\\\n",
    "                .pivot(\"SexCd\", [1, 2])\\\n",
    "                .agg(*AGGR)\n",
    "\n",
    "\n",
    "df2 = multi_aggr(df)\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Broadcast small table in a join to speed up the process\n",
    "def fast_join(big_table, small_table):\n",
    "    return big_table.join(\n",
    "        F.broadcast(small_table).coalesce(1),\n",
    "        \"PK\",\n",
    "        \"left\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+----+-------------------+\n",
      "|Firstname|Lastname| Age|   array_of_strings|\n",
      "+---------+--------+----+-------------------+\n",
      "|    James|    Bond|  43|      [chat, chien]|\n",
      "|   Pierre|     Bin|  54|[pizza, milk, null]|\n",
      "|     Lara|   Tempo|null|           [US, FR]|\n",
      "+---------+--------+----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Create a table form scratch\n",
    "def create_df():\n",
    "    my_schema = T.StructType([\n",
    "            T.StructField(\"Firstname\", T.StringType()),\n",
    "            T.StructField(\"Lastname\", T.StringType()),\n",
    "            T.StructField(\"Age\", T.IntegerType()),\n",
    "            T.StructField(\"array_of_strings\", T.ArrayType(T.StringType()))\n",
    "        ])\n",
    "\n",
    "    my_data = [\n",
    "        {\"Firstname\": \"James\", \"Lastname\": \"Bond\", \"Age\": 43, \"array_of_strings\": [\"chat\", \"chien\"]},\n",
    "        {\"Firstname\": \"Pierre\", \"Lastname\": \"Bin\", \"Age\": 54, \"array_of_strings\": [\"pizza\", \"milk\", None]},\n",
    "        {\"Firstname\": \"Lara\", \"Lastname\": \"Tempo\", \"Age\": None, \"array_of_strings\": [\"US\", \"FR\"]}\n",
    "    ]\n",
    "\n",
    "    return spark.createDataFrame(my_data, my_schema)\n",
    "\n",
    "\n",
    "my_df = create_df()\n",
    "my_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Join on levenstein distance condition\n",
    "def special_cond_join(table1, table2):\n",
    "    join_cond = (\n",
    "        (F.levenshtein(df1[\"Firstname\"], df2[\"prenom\"]) < 5)\n",
    "        &\n",
    "        (table1[\"years_old\"] == table2[\"age\"])\n",
    "    )\n",
    "    return table1.join(table2, join_cond, \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### String cleaner function using regex\n",
    "def cleaner(table, list_cols):\n",
    "    # remove block spaces bigger than 1 and trim\n",
    "    for c in list_cols:\n",
    "        table = table.withColumn(\"cleaned_\" + c, F.trim(F.regexp_replace(c, r'(\\s{2,})', '')))\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+-------+\n",
      "|prenom|nom_de_famille|new_age|\n",
      "+------+--------------+-------+\n",
      "| James|          Bond|     45|\n",
      "|Pierre|           Bin|     56|\n",
      "|  Lara|         Tempo|   null|\n",
      "+------+--------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Mapping function using SQL like statements\n",
    "def mapper(table):\n",
    "    my_mapings = [\n",
    "        \"Firstname as prenom\",\n",
    "        \"Lastname as nom_de_famille\",\n",
    "        \"Age + 2 as new_age\"\n",
    "    ]\n",
    "    return table.selectExpr(my_mapings)\n",
    "\n",
    "test = mapper(my_df)\n",
    "test.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
